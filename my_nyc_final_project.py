# -*- coding: utf-8 -*-
"""Copy of nyc_final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gFj3v2aGca6Pt09G15Sq5LPNhGeihbLo
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd 
import numpy as np
import seaborn as sns


import datetime as dt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

from google.colab import drive
drive.mount('/content/drive')

dataset = pd.read_csv('/content/drive/MyDrive/ml/NYC_Project/nyc_taxi_trip_duration.csv', nrows=30000)

# dataset['pickup_datetime'] = pd.to_datetime(dataset['pickup_datetime'], format = '%d-%m-%Y %H:%M')
# dataset['dropoff_datetime'] = pd.to_datetime(dataset['dropoff_datetime'], format = '%d-%m-%Y %H:%M')

# dataset['pickup_hour'] = dataset['pickup_datetime'].dt.hour
# dataset['pickup_weekday'] = dataset['pickup_datetime'].dt.weekday
# dataset['pickup_day'] = dataset['pickup_datetime'].dt.day
# dataset['pickup_month'] = dataset['pickup_datetime'].dt.month
# dataset['pickup_year'] = dataset['pickup_datetime'].dt.year

# dataset['dropoff_hour'] = dataset['dropoff_datetime'].dt.hour
# dataset['dropoff_day'] = dataset['dropoff_datetime'].dt.day
# dataset['dropoff_month'] = dataset['dropoff_datetime'].dt.month
# dataset['dropoff_year'] = dataset['dropoff_datetime'].dt.year
# dataset['dropoff_weekday'] = dataset['dropoff_datetime'].dt.weekday

dataset = dataset.drop(['id','pickup_datetime', 'dropoff_datetime','store_and_fwd_flag', 'vendor_id'], axis=1)
# df = df.drop('column_name', axis=1)

print(len(dataset))
dataset.head()
dataset.dtypes

print(dataset.info(memory_usage='deep'))

# split dataset
x = dataset.iloc[:, 0:3]
x = dataset.drop(['trip_duration'], axis=1)
y = dataset['trip_duration']
train_x,test_x,train_y,test_y = train_test_split(x, y, random_state = 56)

print(len(train_x))
print(len(train_y))
print(len(test_x))
print(len(test_y))

#Feature scaling
sc_x = StandardScaler()
x_train = sc_x.fit_transform(train_x)
x_test = sc_x.transform(test_x)

import math
math.sqrt(len(test_y))

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
x_scaled = scaler.fit_transform(x)

x = pd.DataFrame(x_scaled, columns = x.columns)

y.head()

x.head()

#importing KNN classifier and metric F1score
from sklearn.neighbors import KNeighborsClassifier as KNN
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error as mse

reg = KNN(n_neighbors = 15)

# Fitting the model
reg.fit(train_x, train_y)

# Predicting over the Train Set and calculating MSE
test_predict = reg.predict(test_x)
k = mse(test_predict, test_y)
print('Test MSE    ', k )

def Elbow(K):
  #initiating empty list
    test_mse = []
  
  #training model for evey value of K
    for i in K:
        #Instance of KNN
        reg = KNN(n_neighbors = i)
        reg.fit(train_x, train_y)
        #Appending mse value to empty list claculated using the predictions
        tmp = reg.predict(test_x)
        tmp = mse(tmp,test_y)
        test_mse.append(tmp)
    
    return test_mse

#Defining K range
k = range(1, 50,2)

# calling above defined function
test = Elbow(k)

# plotting the Curves
import matplotlib.pyplot as plt

plt.plot(k, test)
plt.xlabel('K Neighbors')
plt.ylabel('Test error')
plt.title('Elbow Curve for test')

# Creating instance of KNN
reg = KNN(n_neighbors = 9)

# Fitting the model
reg.fit(train_x, train_y)

# Predicting over the Train Set and calculating F1
test_predict = reg.predict(test_x)
k = mse(test_predict, test_y)
print('Test MSE    ', k )

